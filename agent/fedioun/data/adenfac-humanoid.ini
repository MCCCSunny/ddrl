[simulation]
max_episode=20000
test_episode_per_episode=1
test_episode_at_end=0
dump_log_each=1
display_log_each=1
save_agent_each=5000

[environment]
#during one episode, the simulator can iterate over multiple instance
#for instance with a stochastic environment
instance_per_episode=1

#to limit the number of step for one instance
max_step_per_instance=1000
additional_sensors=false
apply_armature=true
damping=0
approx_ground=1
soft_cfm=0.001
slip1=-1
slip2=-1
soft_erp=-1
bounce_ground=0.05
bounce_vel=0.3
control=0
reapply_motors=true
reupdate_state=false
reward_scale_lvc=5.
reward_penalty_dead=0
reward_alive_bonus=3


[agent]
gamma=0.99
decision_each=1

#policy
noise=0.001
gaussian_policy=true

hidden_unit_q=50:25
hidden_unit_a=50:25

#learning (to test)
reset_qnn=false
reset_ann=false
inverting_grad=true
nb_actor_updates=1
nb_critic_updates=1
nb_fitted_updates=10
nb_internal_critic_updates=1
weighting_strategy=0

#fixed from ddpg:
mini_batch_size=1
#replay_memory=1000000
replay_memory=1000
alpha_a=0.01
alpha_v=0.001
batch_norm=0
decay_v=-1
last_layer_actor=0

#fixed others ideas
retrace_lambda=true
hidden_layer_type=1
replay_traj_size=1
lambda=0.6
lambda_only=false
